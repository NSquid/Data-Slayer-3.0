{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de363c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenne\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8077e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee4f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIRS = [\"./train/drowsiness_separated/\", \"./train/non-drowsiness_separated/\"]\n",
    "OUTPUT_DIRS = [\"./output/drowsiness_faces/\", \"./output/non-drowsiness_faces/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d12c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CSV = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396347e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 30\n",
    "OUT_SIZE = (224, 224)\n",
    "MARGIN = 0.35\n",
    "MIN_CONFIDENCE = 0.5\n",
    "KEEP_ALL = True\n",
    "\n",
    "MTCNN_DEVICE = DEVICE\n",
    "MTCNN_THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d52ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_frame_indices(total, num):\n",
    "    if total <= 0:\n",
    "        return [0] * num\n",
    "    idxs = np.linspace(0, total - 1, num)\n",
    "    return [int(round(i)) for i in idxs]\n",
    "\n",
    "def expand_bbox(x, y, w, h, fw, fh, frac):\n",
    "    dw, dh = int(w * frac), int(h * frac)\n",
    "    x0 = max(0, x - dw)\n",
    "    y0 = max(0, y - dh)\n",
    "    x1 = min(fw, x + w + dw)\n",
    "    y1 = min(fh, y + h + dh)\n",
    "    return (x0, y0, x1 - x0, y1 - y0)\n",
    "\n",
    "def crop_and_resize(frame, bbox, out_size):\n",
    "    x, y, w, h = bbox\n",
    "    x2, y2 = x + w, y + h\n",
    "    hF, wF = frame.shape[:2]\n",
    "\n",
    "    x, y = max(0, x), max(0, y)\n",
    "    x2, y2 = min(wF, x2), min(hF, y2)\n",
    "\n",
    "    crop = frame[y:y2, x:x2]\n",
    "\n",
    "    if crop.size == 0:\n",
    "        # fallback\n",
    "        s = min(hF, wF)\n",
    "        cx, cy = wF // 2, hF // 2\n",
    "        crop = frame[cy-s//2:cy+s//2, cx-s//2:cx+s//2]\n",
    "\n",
    "    return cv2.resize(crop, out_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e290bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=str(DEVICE))\n",
    "\n",
    "def extract_video_to_jpg(video_path, out_dir, num_frames=30, out_size=OUT_SIZE, margin=0.35):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open:\", video_path)\n",
    "        return False\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = sample_frame_indices(total_frames, num_frames)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    prev_bbox = None\n",
    "\n",
    "    for idx_no, frame_idx in enumerate(frame_indices, start=1):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ok, frame = cap.read()\n",
    "\n",
    "        if not ok:\n",
    "            # fallback replicate last saved frame\n",
    "            if idx_no > 1:\n",
    "                last_path = os.path.join(out_dir, f\"{idx_no-1:02d}.jpg\")\n",
    "                out_path = os.path.join(out_dir, f\"{idx_no:02d}.jpg\")\n",
    "                if os.path.exists(last_path):\n",
    "                    img = cv2.imread(last_path)\n",
    "                    cv2.imwrite(out_path, img)\n",
    "                else:\n",
    "                    blank = np.zeros((out_size[1], out_size[0], 3), np.uint8)\n",
    "                    cv2.imwrite(out_path, blank)\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes, _ = mtcnn.detect(rgb)\n",
    "\n",
    "        if boxes is None or len(boxes) == 0:\n",
    "            if prev_bbox is None:\n",
    "                # center square fallback\n",
    "                hF, wF = frame.shape[:2]\n",
    "                s = min(hF, wF)\n",
    "                cx, cy = wF//2, hF//2\n",
    "                bbox = (cx - s//2, cy - s//2, s, s)\n",
    "            else:\n",
    "                bbox = prev_bbox\n",
    "        else:\n",
    "            # pick largest box\n",
    "            areas = [(b[2]-b[0])*(b[3]-b[1]) for b in boxes]\n",
    "            i = int(np.argmax(areas))\n",
    "            x1, y1, x2, y2 = boxes[i]\n",
    "            bbox = (int(x1), int(y1), int(x2 - x1), int(y2 - y1))\n",
    "\n",
    "        bbox_exp = expand_bbox(*bbox, frame.shape[1], frame.shape[0], margin)\n",
    "        face = crop_and_resize(frame, bbox_exp, out_size)\n",
    "        prev_bbox = bbox_exp\n",
    "\n",
    "        out_path = os.path.join(out_dir, f\"{idx_no:02d}.jpg\")\n",
    "        cv2.imwrite(out_path, face)\n",
    "\n",
    "    cap.release()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d975c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_to_jpg(video_dir, output_dir, label_csv=None):\n",
    "    entries = []\n",
    "\n",
    "    if label_csv is not None:\n",
    "        df = pd.read_csv(label_csv)\n",
    "        if \"video_filename\" in df.columns and \"label\" in df.columns:\n",
    "            entries = list(zip(df.video_filename, df.label))\n",
    "        else:\n",
    "            entries = [(r.iloc[0], r.iloc[1]) for _, r in df.iterrows()]\n",
    "    else:\n",
    "        for fn in sorted(os.listdir(video_dir)):\n",
    "            if fn.lower().endswith((\".mp4\",\".avi\",\".mkv\",\".mov\",\".webm\")):\n",
    "                entries.append((fn, \"\"))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for filename, label in tqdm(entries, desc=\"Extracting frames\"):\n",
    "        in_path = os.path.join(video_dir, filename)\n",
    "\n",
    "        # out folder: videos/output/video_name/\n",
    "        folder_name = os.path.splitext(filename)[0]\n",
    "        out_folder = os.path.join(output_dir, folder_name)\n",
    "\n",
    "        ok = extract_video_to_jpg(in_path, out_folder,\n",
    "                                  NUM_FRAMES, OUT_SIZE, MARGIN)\n",
    "\n",
    "        results.append({\n",
    "            \"video\": filename,\n",
    "            \"out_folder\": out_folder,\n",
    "            \"label\": label,\n",
    "            \"success\": ok\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(os.path.join(output_dir, \"manifest.csv\"), index=False)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72a2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames(folder, cols=6, figsize=(12,8)):\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\".jpg\")])\n",
    "    rows = int(np.ceil(len(files)/cols))\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for i, fn in enumerate(files):\n",
    "        img = cv2.imread(os.path.join(folder, fn))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(fn)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4920a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames:  52%|█████▏    | 31/60 [03:05<02:57,  6.11s/it]"
     ]
    }
   ],
   "source": [
    "for VIDEO_DIR, OUTPUT_DIR in zip(VIDEO_DIRS, OUTPUT_DIRS):\n",
    "    manifest = batch_process_to_jpg(VIDEO_DIR, OUTPUT_DIR, LABEL_CSV)\n",
    "    manifest.head()\n",
    "\n",
    "    first_ok = manifest[manifest.success].head(1)\n",
    "    if len(first_ok) > 0:\n",
    "        folder = first_ok.iloc[0].out_folder\n",
    "        print(\"Showing:\", folder)\n",
    "        show_frames(folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
