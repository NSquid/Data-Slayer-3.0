{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96532a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd43ea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì SequenceAugmenter class defined\n"
     ]
    }
   ],
   "source": [
    "class SequenceAugmenter:\n",
    "    \"\"\"\n",
    "    Augmentasi untuk sequence frames wajah drowsiness detection.\n",
    "    Setiap sequence (30 frame) akan diaugmentasi dengan 5 variasi.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def horizontal_flip(image):\n",
    "        \"\"\"Flip horizontal untuk simulasi arah pandang berbeda\"\"\"\n",
    "        return cv2.flip(image, 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def brightness_adjust(image, beta=15):\n",
    "        \"\"\"Adjust brightness ¬±15 untuk simulasi pencahayaan berbeda\"\"\"\n",
    "        return cv2.convertScaleAbs(image, alpha=1.0, beta=beta)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate(image, angle=5):\n",
    "        \"\"\"Rotasi ¬±5¬∞ untuk simulasi kepala miring\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        return cv2.warpAffine(image, M, (w, h))\n",
    "    \n",
    "    @staticmethod\n",
    "    def gaussian_blur(image, kernel_size=(3, 3)):\n",
    "        \"\"\"Gaussian blur untuk simulasi kamera kurang fokus\"\"\"\n",
    "        return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    \n",
    "    def augment_sequence(self, sequence_folder, output_base_folder, base_name):\n",
    "        \"\"\"\n",
    "        Augmentasi satu sequence folder (30 frame) menjadi 5 versi\n",
    "        \"\"\"\n",
    "        from pathlib import Path\n",
    "        \n",
    "        augmentation_configs = [\n",
    "            ('_original', None),  # Original (just copy)\n",
    "            ('_hflip', self.horizontal_flip),\n",
    "            ('_bright', lambda img: self.brightness_adjust(img, beta=15)),\n",
    "            ('_rot', lambda img: self.rotate(img, angle=5)),\n",
    "            ('_blur', lambda img: self.gaussian_blur(img, kernel_size=(3, 3)))\n",
    "        ]\n",
    "        \n",
    "        # Get all frame files\n",
    "        frame_files = sorted([f for f in os.listdir(sequence_folder) if f.endswith('.jpg')])\n",
    "        \n",
    "        if len(frame_files) == 0:\n",
    "            print(f\"‚ö†Ô∏è  No frames found in {sequence_folder}\")\n",
    "            return 0\n",
    "        \n",
    "        created_folders = []\n",
    "        \n",
    "        # Apply each augmentation\n",
    "        for suffix, aug_func in augmentation_configs:\n",
    "            # Create output folder\n",
    "            output_folder = Path(output_base_folder) / f\"{base_name}{suffix}\"\n",
    "            output_folder.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Process each frame\n",
    "            for frame_file in frame_files:\n",
    "                frame_path = os.path.join(sequence_folder, frame_file)\n",
    "                output_path = output_folder / frame_file\n",
    "                \n",
    "                # Read image\n",
    "                img = cv2.imread(frame_path)\n",
    "                \n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Apply augmentation (or just copy if original)\n",
    "                if aug_func is not None:\n",
    "                    img_aug = aug_func(img)\n",
    "                else:\n",
    "                    img_aug = img\n",
    "                \n",
    "                # Save augmented frame\n",
    "                cv2.imwrite(str(output_path), img_aug)\n",
    "            \n",
    "            created_folders.append(output_folder.name)\n",
    "        \n",
    "        return len(augmentation_configs)\n",
    "\n",
    "print(\"‚úì SequenceAugmenter class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae40ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA AUGMENTATION FOR DROWSINESS DETECTION\n",
      "================================================================================\n",
      "\n",
      "üìÅ Processing drowsiness_faces:\n",
      "   Found 60 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Augmenting drowsiness_faces: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:15<00:00,  3.97it/s]\n",
      "   Augmenting drowsiness_faces: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:15<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Completed 60 sequences ‚Üí 300 augmented versions\n",
      "\n",
      "üìÅ Processing non-drowsiness_faces:\n",
      "   Found 60 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Augmenting non-drowsiness_faces: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:14<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Completed 60 sequences ‚Üí 300 augmented versions\n",
      "\n",
      "================================================================================\n",
      "AUGMENTATION COMPLETE!\n",
      "================================================================================\n",
      "Original sequences:   120\n",
      "Augmented versions:   600\n",
      "Total sequences:      600\n",
      "Augmentation factor:  5x\n",
      "Output directory:     c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output_augmented\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Augmentasi semua data\n",
    "from pathlib import Path\n",
    "\n",
    "input_dir = Path(r\"c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output\")\n",
    "output_dir = Path(r\"c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output_augmented\")\n",
    "\n",
    "augmenter = SequenceAugmenter()\n",
    "\n",
    "categories = [\n",
    "    ('drowsiness_faces', 'drowsiness_faces'),\n",
    "    ('non-drowsiness_faces', 'non-drowsiness_faces')\n",
    "]\n",
    "\n",
    "total_original = 0\n",
    "total_augmented = 0\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA AUGMENTATION FOR DROWSINESS DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for input_category, output_category in categories:\n",
    "    input_cat_dir = input_dir / input_category\n",
    "    output_cat_dir = output_dir / output_category\n",
    "    \n",
    "    if not input_cat_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è  Directory not found: {input_cat_dir}\")\n",
    "        continue\n",
    "    \n",
    "    # Create output category directory\n",
    "    output_cat_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all sequence folders\n",
    "    sequence_folders = [f for f in os.listdir(input_cat_dir) \n",
    "                      if os.path.isdir(os.path.join(input_cat_dir, f)) \n",
    "                      and f != \"manifest.csv\"]\n",
    "    \n",
    "    print(f\"\\nüìÅ Processing {input_category}:\")\n",
    "    print(f\"   Found {len(sequence_folders)} sequences\")\n",
    "    \n",
    "    # Process each sequence with progress bar\n",
    "    for seq_folder in tqdm(sequence_folders, desc=f\"   Augmenting {input_category}\"):\n",
    "        seq_path = input_cat_dir / seq_folder\n",
    "        \n",
    "        # Augment this sequence\n",
    "        n_versions = augmenter.augment_sequence(seq_path, output_cat_dir, seq_folder)\n",
    "        \n",
    "        if n_versions > 0:\n",
    "            total_original += 1\n",
    "            total_augmented += n_versions\n",
    "    \n",
    "    print(f\"   ‚úì Completed {len(sequence_folders)} sequences ‚Üí {len(sequence_folders) * 5} augmented versions\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AUGMENTATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Original sequences:   {total_original}\")\n",
    "print(f\"Augmented versions:   {total_augmented}\")\n",
    "print(f\"Total sequences:      {total_augmented}\")\n",
    "print(f\"Augmentation factor:  5x\")\n",
    "print(f\"Output directory:     {output_dir}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "346f5069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AUGMENTED DATASET INFO\n",
      "================================================================================\n",
      "Total data: 600\n",
      "Drowsiness samples: 300\n",
      "Non-drowsiness samples: 300\n",
      "\n",
      "Original dataset: 120 sequences\n",
      "Augmented dataset: 600 sequences\n",
      "Increase: 5.0x\n",
      "\n",
      "Menggunakan Leave-One-Out Cross Validation\n",
      "Setiap fold: 599 training, 1 validation\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Update dataset untuk menggunakan data yang sudah diaugmentasi\n",
    "# CATATAN: Jalankan cell augmentasi terlebih dahulu sebelum menjalankan cell ini!\n",
    "\n",
    "output_dir_augmented = r\"c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output_augmented\"\n",
    "drowsiness_dir_aug = os.path.join(output_dir_augmented, \"drowsiness_faces\")\n",
    "non_drowsiness_dir_aug = os.path.join(output_dir_augmented, \"non-drowsiness_faces\")\n",
    "\n",
    "# Cek apakah folder augmented sudah ada\n",
    "if not os.path.exists(output_dir_augmented):\n",
    "    print(f\"‚ö†Ô∏è  Folder augmented belum ada: {output_dir_augmented}\")\n",
    "    print(\"‚ö†Ô∏è  Silakan jalankan cell augmentasi terlebih dahulu!\")\n",
    "    print(\"\\nSkipping augmented dataset loading...\")\n",
    "else:\n",
    "    # Kumpulkan semua folder video dan labelnya dari data augmented\n",
    "    video_folders_aug = []\n",
    "    labels_aug = []\n",
    "\n",
    "    # Label 1 untuk drowsiness\n",
    "    for folder_name in os.listdir(drowsiness_dir_aug):\n",
    "        folder_path = os.path.join(drowsiness_dir_aug, folder_name)\n",
    "        if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "            video_folders_aug.append(folder_path)\n",
    "            labels_aug.append(1)  # drowsiness = 1\n",
    "\n",
    "    # Label 0 untuk non-drowsiness\n",
    "    for folder_name in os.listdir(non_drowsiness_dir_aug):\n",
    "        folder_path = os.path.join(non_drowsiness_dir_aug, folder_name)\n",
    "        if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "            video_folders_aug.append(folder_path)\n",
    "            labels_aug.append(0)  # non-drowsiness = 0\n",
    "\n",
    "    # Buat dataset dengan data augmented\n",
    "    full_dataset_aug = DrowsinessDataset(video_folders_aug, labels_aug, transform=transform)\n",
    "\n",
    "    # Print informasi dataset\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"AUGMENTED DATASET INFO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total data: {len(video_folders_aug)}\")\n",
    "    print(f\"Drowsiness samples: {sum(labels_aug)}\")\n",
    "    print(f\"Non-drowsiness samples: {len(labels_aug) - sum(labels_aug)}\")\n",
    "    print(f\"\\nOriginal training dataset: {len(train_video_folders)} sequences\")\n",
    "    print(f\"Augmented training dataset: {len(video_folders_aug)} sequences\")\n",
    "    print(f\"Increase: {len(video_folders_aug) / len(train_video_folders):.1f}x\")\n",
    "    print(f\"\\nValidation dataset tetap: {len(val_video_folders)} sequences\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Update train_dataset dengan augmented version\n",
    "    train_dataset = DrowsinessDataset(video_folders_aug, labels_aug, transform=transform)\n",
    "    print(f\"\\n‚úì Training dataset updated dengan augmented data\")\n",
    "    print(f\"  Training: {len(train_dataset)} samples\")\n",
    "    print(f\"  Validation: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3134528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET INFORMATION\n",
      "================================================================================\n",
      "\n",
      "TRAINING SET:\n",
      "  Total data: 600\n",
      "  Drowsiness samples: 300\n",
      "  Non-drowsiness samples: 300\n",
      "\n",
      "VALIDATION SET:\n",
      "  Total data: 150\n",
      "  Drowsiness samples: 45\n",
      "  Non-drowsiness samples: 105\n",
      "\n",
      "Total samples: 750\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dataset class untuk memuat sequential frames\n",
    "class DrowsinessDataset(Dataset):\n",
    "    def __init__(self, video_folders, labels, transform=None, num_frames=30):\n",
    "        self.video_folders = video_folders\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_folders)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        folder_path = self.video_folders[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load semua frames dari folder\n",
    "        frames = []\n",
    "        for i in range(1, self.num_frames + 1):\n",
    "            frame_path = os.path.join(folder_path, f\"{i:02d}.jpg\")\n",
    "            \n",
    "            if os.path.exists(frame_path):\n",
    "                img = Image.open(frame_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                frames.append(img)\n",
    "            else:\n",
    "                # Jika frame tidak ada, gunakan frame kosong\n",
    "                if self.transform:\n",
    "                    img = self.transform(Image.new('RGB', (224, 224)))\n",
    "                else:\n",
    "                    img = torch.zeros(3, 224, 224)\n",
    "                frames.append(img)\n",
    "        \n",
    "        # Stack frames menjadi tensor (num_frames, channels, height, width)\n",
    "        frames = torch.stack(frames)\n",
    "        \n",
    "        return frames, label\n",
    "\n",
    "# Transform untuk preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Path ke folder output untuk TRAINING\n",
    "output_dir = r\"c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output_augmented\"\n",
    "drowsiness_dir = os.path.join(output_dir, \"drowsiness_faces\")\n",
    "non_drowsiness_dir = os.path.join(output_dir, \"non-drowsiness_faces\")\n",
    "\n",
    "# Kumpulkan semua folder video dan labelnya untuk TRAINING\n",
    "train_video_folders = []\n",
    "train_labels = []\n",
    "\n",
    "# Label 1 untuk drowsiness\n",
    "for folder_name in os.listdir(drowsiness_dir):\n",
    "    folder_path = os.path.join(drowsiness_dir, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "        train_video_folders.append(folder_path)\n",
    "        train_labels.append(1)  # drowsiness = 1\n",
    "\n",
    "# Label 0 untuk non-drowsiness\n",
    "for folder_name in os.listdir(non_drowsiness_dir):\n",
    "    folder_path = os.path.join(non_drowsiness_dir, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "        train_video_folders.append(folder_path)\n",
    "        train_labels.append(0)  # non-drowsiness = 0\n",
    "\n",
    "# Path ke folder output_val untuk VALIDATION\n",
    "val_dir = r\"c:\\Users\\andre\\Documents\\Binus\\Lomba\\DataSlayer 3\\output_val\"\n",
    "val_drowsy_dir = os.path.join(val_dir, \"1\")  # Label 1 = drowsy\n",
    "val_non_drowsy_dir = os.path.join(val_dir, \"0\")  # Label 0 = non-drowsy\n",
    "\n",
    "# Kumpulkan semua folder video dan labelnya untuk VALIDATION\n",
    "val_video_folders = []\n",
    "val_labels = []\n",
    "\n",
    "# Label 1 untuk drowsiness (folder \"1\")\n",
    "for folder_name in os.listdir(val_drowsy_dir):\n",
    "    folder_path = os.path.join(val_drowsy_dir, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "        val_video_folders.append(folder_path)\n",
    "        val_labels.append(1)\n",
    "\n",
    "# Label 0 untuk non-drowsiness (folder \"0\")\n",
    "for folder_name in os.listdir(val_non_drowsy_dir):\n",
    "    folder_path = os.path.join(val_non_drowsy_dir, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name != \"manifest.csv\":\n",
    "        val_video_folders.append(folder_path)\n",
    "        val_labels.append(0)\n",
    "\n",
    "# Buat dataset untuk TRAINING dan VALIDATION\n",
    "train_dataset = DrowsinessDataset(train_video_folders, train_labels, transform=transform)\n",
    "val_dataset = DrowsinessDataset(val_video_folders, val_labels, transform=transform)\n",
    "\n",
    "# Print informasi dataset\n",
    "print(f\"=\"*80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\nTRAINING SET:\")\n",
    "print(f\"  Total data: {len(train_video_folders)}\")\n",
    "print(f\"  Drowsiness samples: {sum(train_labels)}\")\n",
    "print(f\"  Non-drowsiness samples: {len(train_labels) - sum(train_labels)}\")\n",
    "print(f\"\\nVALIDATION SET:\")\n",
    "print(f\"  Total data: {len(val_video_folders)}\")\n",
    "print(f\"  Drowsiness samples: {sum(val_labels)}\")\n",
    "print(f\"  Non-drowsiness samples: {len(val_labels) - sum(val_labels)}\")\n",
    "print(f\"\\nTotal samples: {len(train_video_folders) + len(val_video_folders)}\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad09ba",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Augmentasi data untuk meningkatkan jumlah training samples dari ~120 menjadi ~600 sequences.\n",
    "\n",
    "**Teknik Augmentasi:**\n",
    "1. **Original** - Copy asli\n",
    "2. **Horizontal Flip** - Simulasi arah pandang berbeda\n",
    "3. **Brightness Adjust** - Simulasi pencahayaan berbeda (+15)\n",
    "4. **Rotation** - Simulasi kepala miring (¬±5¬∞)\n",
    "5. **Gaussian Blur** - Simulasi kamera kurang fokus (3√ó3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8ab273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc01202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce GTX 1650 Ti\n",
      "CUDA Version: 11.8\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "# CUDA optimization\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc109d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=256, freeze=True):\n",
    "        super().__init__()\n",
    "        # Load pretrained EfficientNetB0\n",
    "        self.effnet = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Freeze backbone\n",
    "        if freeze:\n",
    "            for param in self.effnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Bottleneck layer: 1280 -> 256\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(1280, feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)  # Reduced dropout for small dataset\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B*T, C, H, W)\n",
    "        features = self.effnet(x)  # (B*T, 1280)\n",
    "        features = self.bottleneck(features)  # (B*T, 256)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7272c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=128, num_layers=1, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=0.0  # No dropout karena 1 layer\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, T, F)\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        # out: (B, T, hidden_size * 2) jika bidirectional\n",
    "        # Ambil output di time step terakhir\n",
    "        last_out = out[:, -1, :]  # (B, hidden_size * 2)\n",
    "        return last_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8596512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=256, hidden_size=64, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Reduced dropout for small dataset\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc93f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsinessDetector(nn.Module):\n",
    "    def __init__(self, feature_dim=256, lstm_hidden=128, mlp_hidden=64, freeze_cnn=True):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = EfficientNetFeatureExtractor(feature_dim=feature_dim, freeze=freeze_cnn)\n",
    "        \n",
    "        lstm_output_size = lstm_hidden * 2  # bidirectional\n",
    "        self.temporal_encoder = LSTMEncoder(input_size=feature_dim, hidden_size=lstm_hidden, bidirectional=True)\n",
    "        self.classifier = MLPClassifier(input_size=lstm_output_size, hidden_size=mlp_hidden, num_classes=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        \n",
    "        # Reshape untuk feature extraction\n",
    "        x = x.view(B * T, C, H, W)  # (B*T, C, H, W)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)  # (B*T, feature_dim)\n",
    "        \n",
    "        # Reshape kembali untuk LSTM\n",
    "        features = features.view(B, T, -1)  # (B, T, feature_dim)\n",
    "        \n",
    "        # LSTM encoding\n",
    "        lstm_out = self.temporal_encoder(features)  # (B, lstm_hidden*2)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(lstm_out)  # (B, 1)\n",
    "        \n",
    "        return logits.squeeze(-1)  # (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883734d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "Total parameters: 4,747,261\n",
      "Trainable parameters: 739,713\n",
      "Frozen parameters: 4,007,548\n"
     ]
    }
   ],
   "source": [
    "# Model akan dibuat ulang di setiap fold LOOCV\n",
    "# Ini hanya untuk melihat arsitektur\n",
    "model_template = DrowsinessDetector(\n",
    "    feature_dim=256,\n",
    "    lstm_hidden=128,\n",
    "    mlp_hidden=64,\n",
    "    freeze_cnn=True\n",
    ").to(device)\n",
    "\n",
    "# Hitung parameter\n",
    "total_params = sum(p.numel() for p in model_template.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_template.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model Architecture:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e1a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (Training Set):\n",
      "  Non-drowsy: 300\n",
      "  Drowsy: 300\n",
      "  Pos weight for BCE Loss: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Hitung class weights untuk menangani imbalance (dari training set)\n",
    "num_drowsy = sum(train_labels)\n",
    "num_non_drowsy = len(train_labels) - num_drowsy\n",
    "pos_weight_value = num_non_drowsy / num_drowsy\n",
    "\n",
    "print(f\"Class distribution (Training Set):\")\n",
    "print(f\"  Non-drowsy: {num_non_drowsy}\")\n",
    "print(f\"  Drowsy: {num_drowsy}\")\n",
    "print(f\"  Pos weight for BCE Loss: {pos_weight_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1950e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, use_amp=True, verbose=False):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    \n",
    "    for batch_idx, (frames, labels) in enumerate(train_loader):\n",
    "        frames = frames.to(device, non_blocking=False)  # Changed to blocking to avoid memory fragmentation\n",
    "        labels = labels.float().to(device, non_blocking=False)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_amp and torch.cuda.is_available():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(frames)\n",
    "                loss = criterion(logits, labels)\n",
    "            \n",
    "            if torch.isnan(loss):\n",
    "                if verbose:\n",
    "                    print(f\"‚ö†Ô∏è NaN loss detected at batch {batch_idx}\")\n",
    "                continue\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(frames)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            if torch.isnan(loss):\n",
    "                if verbose:\n",
    "                    print(f\"‚ö†Ô∏è NaN loss detected at batch {batch_idx}\")\n",
    "                continue\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Clear GPU cache after each batch to prevent memory buildup\n",
    "        if torch.cuda.is_available():\n",
    "            del frames, labels, logits, preds\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    epoch_loss = running_loss / max(len(train_loader), 1)\n",
    "    epoch_acc = accuracy_score(targets, predictions) if len(targets) > 0 else 0.0\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate on validation set\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for frames, labels in val_loader:\n",
    "            frames = frames.to(device, non_blocking=False)  # Changed to blocking to avoid memory fragmentation\n",
    "            labels = labels.float().to(device, non_blocking=False)\n",
    "            \n",
    "            logits = model(frames)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Clear GPU cache after each batch to prevent memory buildup\n",
    "            if torch.cuda.is_available():\n",
    "                del frames, labels, logits, preds\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    val_loss = running_loss / max(len(val_loader), 1)\n",
    "    val_acc = accuracy_score(targets, predictions) if len(targets) > 0 else 0.0\n",
    "    val_precision = precision_score(targets, predictions, zero_division=0) if len(targets) > 0 else 0.0\n",
    "    val_recall = recall_score(targets, predictions, zero_division=0) if len(targets) > 0 else 0.0\n",
    "    val_f1 = f1_score(targets, predictions, zero_division=0) if len(targets) > 0 else 0.0\n",
    "    \n",
    "    return val_loss, val_acc, val_precision, val_recall, val_f1, predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc980b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory before training: 1.81 GB\n",
      "================================================================================\n",
      "TRAINING START\n",
      "================================================================================\n",
      "Training samples: 600\n",
      "Validation samples: 150\n",
      "Epochs: 30\n",
      "Batch size: 2\n",
      "Early stopping patience: 15\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Epoch 1/30\n",
      "================================================================================\n",
      "================================================================================\n",
      "TRAINING START\n",
      "================================================================================\n",
      "Training samples: 600\n",
      "Validation samples: 150\n",
      "Epochs: 30\n",
      "Batch size: 2\n",
      "Early stopping patience: 15\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Epoch 1/30\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24708\\2331229661.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24708\\2331229661.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.00 GiB is allocated by PyTorch, and 179.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 77\u001b[0m\n\u001b[0;32m     72\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[0;32m     73\u001b[0m     model, train_loader, criterion, optimizer, device, use_amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m val_loss, val_acc, val_precision, val_recall, val_f1, val_preds, val_targets \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Update learning rate\u001b[39;00m\n\u001b[0;32m     82\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "Cell \u001b[1;32mIn[11], line 65\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[0;32m     62\u001b[0m frames \u001b[38;5;241m=\u001b[39m frames\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 65\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     68\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m, in \u001b[0;36mDrowsinessDetector.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m T, C, H, W)  \u001b[38;5;66;03m# (B*T, C, H, W)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B*T, feature_dim)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Reshape kembali untuk LSTM\u001b[39;00m\n\u001b[0;32m     21\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(B, T, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, T, feature_dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mEfficientNetFeatureExtractor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# x: (B*T, C, H, W)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B*T, 1280)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottleneck(features)  \u001b[38;5;66;03m# (B*T, 256)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\timm\\models\\efficientnet.py:347\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\timm\\models\\efficientnet.py:325\u001b[0m, in \u001b[0;36mEfficientNet.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    323\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, x, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_head(x)\n\u001b[0;32m    327\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\timm\\models\\_efficientnet_blocks.py:329\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    327\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_s2d(x)\n\u001b[0;32m    328\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_s2d(x)\n\u001b[1;32m--> 329\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_pw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    331\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_dw(x)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 2.00 GiB is allocated by PyTorch, and 179.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Training dengan Train/Validation Split\n",
    "num_epochs = 30\n",
    "batch_size = 2  # Reduced from 8 to 2 for 4GB GPU (2 sequences * 30 frames = 60 images)\n",
    "patience = 15\n",
    "\n",
    "# Clear GPU cache before training\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU Memory before training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=0, pin_memory=False)  # Disable pin_memory to save GPU memory\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=0, pin_memory=False)\n",
    "\n",
    "# Initialize model\n",
    "model = DrowsinessDetector(\n",
    "    feature_dim=256,\n",
    "    lstm_hidden=128,\n",
    "    mlp_hidden=64,\n",
    "    freeze_cnn=True\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizer and loss\n",
    "pos_weight = torch.tensor([pos_weight_value]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING START\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Early stopping patience: {patience}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "best_epoch = 0\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, use_amp=True, verbose=False\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1, val_preds, val_targets = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"\\nTrain - Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | \"\n",
    "              f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(f\"LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Early stopping and model saving based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            patience_counter = 0\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            print(f\"‚úì Best model (Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f})\")\n",
    "            \n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'history': history\n",
    "            }, 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Best val loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Best val accuracy: {best_val_acc:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚ö†Ô∏è TRAINING INTERRUPTED BY USER\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if len(history['train_loss']) > 0:\n",
    "        # Save partial model\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'history': history\n",
    "        }, 'interrupted_model.pth')\n",
    "        print(f\"\\nüíæ Model saved to 'interrupted_model.pth'\")\n",
    "        print(f\"Completed {epoch + 1} epochs\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04323bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL LOOCV RESULTS\n",
      "================================================================================\n",
      "\n",
      "Overall Metrics:\n",
      "  Accuracy:      1.0000 (100.00%)\n",
      "  Precision:     1.0000\n",
      "  Recall:        1.0000\n",
      "  F1-Score:      1.0000\n",
      "  F1-Macro:      1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted\n",
      "                 Non-Drowsy  Drowsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\datsci\\lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 Predicted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                 Non-Drowsy  Drowsy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual Non-Drowsy    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m       \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual Drowsy        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m       \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPer-Class Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# Final Evaluation on Validation Set\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL EVALUATION ON VALIDATION SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "val_loss, val_acc, val_precision, val_recall, val_f1, val_preds, val_targets = validate(\n",
    "    model, val_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_true = np.array(val_targets)\n",
    "y_pred = np.array(val_preds)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy:      {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"  Precision:     {val_precision:.4f}\")\n",
    "print(f\"  Recall:        {val_recall:.4f}\")\n",
    "print(f\"  F1-Score:      {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"                 Non-Drowsy  Drowsy\")\n",
    "print(f\"Actual Non-Drowsy    {cm[0,0]:3d}       {cm[0,1]:3d}\")\n",
    "print(f\"Actual Drowsy        {cm[1,0]:3d}       {cm[1,1]:3d}\")\n",
    "\n",
    "print(f\"\\nPer-Class Metrics:\")\n",
    "if cm[0,0] + cm[0,1] > 0:\n",
    "    non_drowsy_acc = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "    print(f\"  Non-Drowsy Accuracy: {non_drowsy_acc:.4f} ({non_drowsy_acc*100:.2f}%)\")\n",
    "if cm[1,0] + cm[1,1] > 0:\n",
    "    drowsy_acc = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "    print(f\"  Drowsy Accuracy:     {drowsy_acc:.4f} ({drowsy_acc*100:.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(history)\n",
    "results_df.to_csv('training_history.csv', index=False)\n",
    "print(f\"\\nTraining history saved to 'training_history.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b069d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correct_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold Number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect (1) / Incorrect (0)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction Correctness per Fold (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcorrect_folds\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m correct)\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     35\u001b[0m              fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yticks([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     37\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yticklabels([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncorrect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'correct_folds' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Training & Validation Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['train_loss'], label='Train Loss', color='blue', linewidth=2)\n",
    "ax.plot(history['val_loss'], label='Val Loss', color='red', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2. Training & Validation Accuracy\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['train_acc'], label='Train Acc', color='blue', linewidth=2)\n",
    "ax.plot(history['val_acc'], label='Val Acc', color='red', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Learning Rate\n",
    "ax = axes[0, 2]\n",
    "ax.plot(history['lr'], color='green', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "ax = axes[1, 0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Non-Drowsy', 'Drowsy'],\n",
    "            yticklabels=['Non-Drowsy', 'Drowsy'])\n",
    "ax.set_title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "\n",
    "# 5. Validation Metrics Over Time\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history['val_precision'], label='Precision', linewidth=2)\n",
    "ax.plot(history['val_recall'], label='Recall', linewidth=2)\n",
    "ax.plot(history['val_f1'], label='F1-Score', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Validation Metrics Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 6. Final Metrics Bar Chart\n",
    "ax = axes[1, 2]\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "metrics_values = [val_acc, val_precision, val_recall, val_f1]\n",
    "bars = ax.bar(metrics_names, metrics_values, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Final Validation Metrics', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar, val in zip(bars, metrics_values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved to 'training_results.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be191a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "Dataset Information:\n",
      "  Total samples: 120\n",
      "  Non-drowsy samples: 60\n",
      "  Drowsy samples: 60\n",
      "  Class balance: 1.00:1\n",
      "\n",
      "Model Architecture:\n",
      "  Feature Extractor: EfficientNetB0 (frozen)\n",
      "  Temporal Encoder: Bidirectional LSTM (hidden=128)\n",
      "  Classifier: MLP (256‚Üí64‚Üí1)\n",
      "  Total parameters: 4,747,261\n",
      "  Trainable parameters: 739,713\n",
      "\n",
      "Training Configuration:\n",
      "  Cross-validation: Leave-One-Out (LOOCV)\n",
      "  Total folds: 120\n",
      "  Epochs per fold: 30\n",
      "  Batch size: 8\n",
      "  Learning rate: 5e-4\n",
      "  Optimizer: Adam\n",
      "  Loss: BCEWithLogitsLoss (pos_weight=1.00)\n",
      "\n",
      "Final Performance:\n",
      "  Accuracy:      1.0000 (100.00%)\n",
      "  Precision:     1.0000\n",
      "  Recall:        1.0000\n",
      "  F1-Score:      1.0000\n",
      "  F1-Macro:      1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "  True Negatives:  1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  True Negatives:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  False Positives: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  False Negatives: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  True Positives:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcm[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# Summary Report\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Training drowsy: {sum(train_labels)}\")\n",
    "print(f\"  Training non-drowsy: {len(train_labels) - sum(train_labels)}\")\n",
    "print(f\"  Validation drowsy: {sum(val_labels)}\")\n",
    "print(f\"  Validation non-drowsy: {len(val_labels) - sum(val_labels)}\")\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Feature Extractor: EfficientNetB0 (frozen)\")\n",
    "print(f\"  Temporal Encoder: Bidirectional LSTM (hidden=128)\")\n",
    "print(f\"  Classifier: MLP (256‚Üí64‚Üí1)\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Total epochs: {len(history['train_loss'])}\")\n",
    "print(f\"  Best epoch: {best_epoch}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Initial learning rate: 5e-4\")\n",
    "print(f\"  Final learning rate: {history['lr'][-1]:.6f}\")\n",
    "print(f\"  Optimizer: Adam\")\n",
    "print(f\"  Loss: BCEWithLogitsLoss (pos_weight={pos_weight_value:.2f})\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau\")\n",
    "\n",
    "print(f\"\\nBest Training Performance:\")\n",
    "print(f\"  Train Loss: {min(history['train_loss']):.4f}\")\n",
    "print(f\"  Train Accuracy: {max(history['train_acc']):.4f} ({max(history['train_acc'])*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nFinal Validation Performance:\")\n",
    "print(f\"  Val Loss:      {val_loss:.4f}\")\n",
    "print(f\"  Val Accuracy:  {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"  Val Precision: {val_precision:.4f}\")\n",
    "print(f\"  Val Recall:    {val_recall:.4f}\")\n",
    "print(f\"  Val F1-Score:  {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives:  {cm[0,0]}\")\n",
    "print(f\"  False Positives: {cm[0,1]}\")\n",
    "print(f\"  False Negatives: {cm[1,0]}\")\n",
    "print(f\"  True Positives:  {cm[1,1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
